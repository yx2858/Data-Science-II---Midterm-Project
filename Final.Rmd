---
title: "A Combined Cohort Study to Predict COVID-19 Recovery Time and Identify Risk Factors for Prolonged Recovery"
author: "Jixin Li (jl6648), Alex McCreight (apm2217), Yueyi Xu (yx2858)"
output: pdf_document
date: "Spring 2024"
geometry: margin=1in
fontsize: 12pt
spacing: double
bibliography: Library.bib
csl: vancouver-superscript.csl
---

```{r libraries-data-cleaning, include = F}
library(tidyverse)
library(glmnet)
library(caret)
library(tidymodels)
library(pls)
library(corrplot)
library(knitr)
library(patchwork)
library(tibble)
library(knitr)
library(kableExtra)


load("recovery.RData")

dat$gender <- as.factor(dat$gender)
dat$race <- as.factor(dat$race)
dat$smoking <- as.factor(dat$smoking)
dat$hypertension <- as.factor(dat$hypertension)
dat$diabetes <- as.factor(dat$diabetes)
dat$vaccine <- as.factor(dat$vaccine)
dat$severity <- as.factor(dat$severity)
dat$study <- as.factor(dat$study)

dat <- dat %>%
  select(-id) %>% 
  mutate(
    gender = case_when(
      dat$gender == 1 ~ "Male",
      TRUE ~ "Female"),
    race = case_when(
      dat$race == 1 ~ "White",
      dat$race == 2 ~ "Asian",
      dat$race == 3 ~ "Black",
      TRUE ~ "Hispanic"),
    smoking = case_when(
      dat$smoking == 0 ~ "Never Smoked",
      dat$smoking == 1 ~ "Former Smoker",
      TRUE ~ "Current Smoker")) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(race = relevel(race, ref = "White"),
         smoking = relevel(smoking, ref = "Never Smoked"),
         study = relevel(study, ref = "B"))
```

## Introduction

The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) was first identified in China in December 2019. Since then, the COVID-19 pandemic has posed a significant public health threat, particularly affecting older adults and individuals with chronic health conditions. Factors such as age, gender, vaccination status, the severity of COVID-19 symptoms, and pre-existing chronic illnesses play a crucial role in determining the recovery time for patients[@Factors].

In this project, we fit various models based on factors that potentially affect COVID-19 recovery time. First, we examine the data and visualize the relationship between risk factors and recovery time, as well as analyzing the correlation between factors. We then use different subsets of predictors to train and fit various types of models, including LASSO, elastic net, ridge regression, partial least squares, and MARS. Finally, we evaluate each model's test error to make our final model selection.

## Exploratory analysis and data visualization

With the goals of developing a prediction model for COVID-19 recovery time and identifying important risk factors for long recovery in mind, we first ran an exploratory analysis of all variables in our data set to visualize their relationship with recovery time. Our findings revealed that recovery time has a small positive correlation with age and weight, and a slightly stronger positive association with BMI. Conversely, height has a small negative relationship with recovery time.

Among the discrete variables, we observed substantial differences in recovery time based on vaccination status as well as COVID-19 severity. Individuals who received the COVID-19 vaccine had shorter recovery times, on average, compared to those who have not received the vaccine (Figure 1a). Additionally, those with "severe" COVID-19 had longer recovery times, on average, compared to those with "non-severe" COVID-19 (Figure 1b).

```{r, echo=FALSE, fig.width=7, fig.height=3}
p1 <- dat %>%
  mutate(vaccine = case_when(
    dat$vaccine == 1 ~ "Vaccinated",
    TRUE ~ "Not vaccinated"
  )) %>% 
  ggplot(aes(x = vaccine, y = recovery_time)) +
    geom_boxplot() +
    theme_classic() + 
    labs(x = "Vaccination Status at Time of Infection", y = "Recovery Time (in days)", title = "Figure 1a")

p2 <- dat %>%
  mutate(severity = case_when(
    dat$severity == 1 ~ "Severe",
    TRUE ~ "Not severe"
  )) %>% 
  ggplot(aes(x = severity, y = recovery_time)) +
    geom_boxplot() +
    theme_classic() + 
    labs(x = "Severity of COVID-19 infection", y = "Recovery Time (in days)", title = "Figure 1b")

p1 + p2
```

Interestingly, we found that those with diabetes had a shorter average time to recovery compared to those without diabetes, which immediately seems counter intuitive (Figure 2). However, upon further literature review, we posit that those with diabetes in these studies either died more quickly compared to those without diabetes, or those with long-COVID and lived most likely had well-managed diabetes and took extra precautions against COVID-19 compared to those without diabetes[@diabetes].

Finally, we observed a significant difference in the variability of recovery times of participants in study A versus study B. The exact reasons for this discrepancy are unclear, however, we hypothesize that study A was conducted when the vaccines were more available leading to reduced variability in recovery time compared to study B. 


```{r, echo = F, fig.width = 5, fig.height = 3, fig.align='center'}
dat %>%
  mutate(diabetes = case_when(
    dat$diabetes == 1 ~ "Has Diabetes",
    TRUE ~ "No Diabetes"
  )) %>% 
  ggplot(aes(x = diabetes, y = recovery_time)) +
    geom_boxplot() +
    theme_classic() + 
    labs(x = "Diabetes Status", y = "Recovery Time (in days)", title = "Figure 2: Diabetes Status vs Time to Recovery")
```

  
## Model training

We used several methods to predict the time to recovery from COVID-19 including:

1. Least Absolute Shrinkage and Selection Operator (LASSO)

2. Elastic Net

3. Ridge Regression

4. Partial Least Squares (PLS)

5. Multivariate Adaptive Regression Splines (MARS)

LASSO, Elastic Net, Ridge Regression, and PLS all assume a linear relationship between the covariates/components and the outcome. Additionally, LASSO, Elastic Net, and Ridge regression all assume that the observations are all independent of each other and that the error terms are normally distributed with constant variance. These three model types all deal with multicollinearity slightly differently. Ridge regression tends to shrink highly correlated predictors towards each other, LASSO is relatively indifferent with highly correlated predictors and will just pick one and ignore the rest, and Elastic Net the most effective of the three to deal with groups of highly correlated predictors. PLS also handles multicollinearity relatively well. Finally, MARS is a non-parameteric technique that does not make explicit assumptions about the functional relationship between the predictors and the outcome. MARS is also unique among these other methods as it will automatically consider interactions between the predictors. While the MARS algorithm itself is assumption-free, the simulation studies used to evaluate its performance all assumed independent predictors and normally distributed error terms with mean 0 and constant variance[@MARS].

To obtain our final model, we considered two subsets of predictors. The first set contained all predictors available in the dataset, while the second set included a selected group of predictors that demonstrated an association with recovery time during the exploratory analysis stage. These predictors were `age`, `height`, `weight`, `gender`, `race`, `smoking`, `hypertension`, `diabetes`, `vaccine`, `severity`, and `study`. For each subset of predictors, we divided the data into training and testing sets using an 80%/20% split. This split allowed us to evaluate the performance of the models on unseen data and assess the generalizability of our model. **NOTE: mention standardization**

We then used the caret package in R to train and tune the models. Specifically, we used the train function, where we tune the hyperparameters using a grid search. For each model type, we defined a grid of hyperparameter values and performed repeated 10-fold cross-validation five times to find the hyperparameter (combination of hyperparameters) that yielded the lowest RMSE value (except for our LASSO model where we used the 1SE rule). For model comparison, we used test RMSE to select our model that best predicts COVID-19 recovery time. 


\newpage


Model Training Procedure:
1. Data Partitioning: The dataset 'dat' and a subset 'dat_subset' are divided into training (80%) and testing (20%) sets to ensure models are evaluated on unseen data.

2. Feature Engineering: Model matrices are created from the training data, excluding the response variable for direct use in the models.

3. Model Tuning and Training: For each model type (LASSO, Ridge, Elastic Net, PLS, MARS), the 'train' function from the 'caret' package is used with a grid of hyperparameters to find the best settings through cross-validation. The process involves:
- Specifying a tuning grid for model parameters (e.g. 'lambda' for regularization strength, 'alpha' for the mix between LASSO and Ridge in Elastic Net).
- Using repeated cross-validation to assess model performance and select the best hyperparameters ('ctrl_SE' for models where selection is based on the one-standard error rule, and 'ctrl_best' for models choosing the best performance).

4. Model Evaluation: Models are evaluated using Resampling statistics (resamp) and comparison of RMSE (Root Mean Square Error) across all models using both the full dataset and the subset.

Final Model Selection:
The final model selection involves comparing the RMSE of each model on the test dataset. The models are ranked based on their performance (lower RMSE values indicate better performance), and the best-performing model(s) can be chosen for further analysis or deployment. 

## Results

The MARS model was selected as the best model for prediction because it achieved the lowest RMSE, which is 17.51607, indicates it would have the best predictive performance. According to the coefficient results, 
the recovery time is 34.9 days when all predictor variables are zero; For every centimeter increase in height from 159.7, the recovery time increases by approximately 9.34 days; For every kilograms increase in weight from 77.8, the recovery time increases by approximately 0.62 days; people who are vaccinated experience a reduced recovery time by approximately 6.7 days compared to those who are not vaccinated; people who have severe symptoms experience a increased recovery time by approximately 7.5 days compared to those who don't have severe symptoms. Therefore, we can conclude that factors such as height, weight, vaccination, and severity are significant factors that affect COVID-19 patients' recovery time.

```{r, echo = F}
tibble(
  Model = c("MARS (Subset)", "MARS", "PLS", "Elastic Net", "LASSO", "Ridge", "Ridge (Subset)", "Elastic Net (Subset)", "PLS (Subset)", "LASSO (Subset)"),
  RMSE = c(17.51607, 17.90665, 18.38267, 18.40800, 19.01320, 19.83322, 20.13261, 20.13263, 20.14682, 20.82849)
) %>% kable(caption = "Comparison of RMSE values for different models")

tibble(
  Variable = c("(Intercept)", 
               "h(159.7-height)", 
               "`h(159.7-height) * h(weight-81.1)`", 
               "`h(159.7-height) *h(weight-81.1)* studyA`", 
               "h(weight-77.8)", 
               "`h(171.7-height) * h(weight-77.8)`", 
               "vaccine1", 
               "`h(171.7-height) *h(weight-77.8)* studyA`", 
               "severity1", 
               "`h(height-159.7) * h(87.3-weight)`", 
               "`h(159.7-height) * studyA`"),
  Coefficients = c(34.88323690, 9.34309220, 5.76534263, -5.30476432, 0.61871036, 0.58372420, -6.70694245, -0.39375665, 7.54439179, 0.05074098, -7.18027109)
) %>% kable(caption = "Coefficients results for MARS model")
```


```{r, inlcude=FALSE}
# set.seed(1)
# trainIndex_sub <- createDataPartition(dat_subset$recovery_time, p = 0.8, list = FALSE)
# training_data_sub <- dat_subset[trainIndex, ]
# testing_data_sub <- dat_subset[-trainIndex, ]
# 
# ctrl_best <- trainControl(method = "repeatedcv",
#                       number = 10,
#                       repeats = 5,
#                       selectionFunction = "best")
# 
# x_sub <- model.matrix(recovery_time ~ ., training_data_sub)[, -1]
# y_sub <- training_data_sub$recovery_time
# 
# # MARS Sub
# 
# mars_fit_sub <- train(x = x_sub,
#                   y = y_sub,
#                  method = "earth",
#                  tuneGrid = mars_grid,
#                  metric = "RMSE",
#                  trControl = ctrl_best)
# 
# ggplot(mars_fit_sub) + theme_classic()
# 
# mars_fit_sub$bestTune
# coef(mars_fit_sub$finalModel)
```


## Conclusions

In this section, summarize your findings from the model analysis and discuss the insights gained into predicting time to recovery from COVID-19.

### Additional Considerations

In your modeling efforts, did you include "study" as a predictor variable? Provide a rationale for your decision, considering the variable's relevance and potential impact on model accuracy and interpretability.

## References